server:
  port: 8888
  shutdown: graceful
spring:
  config:
    activate:
      on-profile: local
  cloud:
    config:
      server:
        git: # config서버 설정 정보가 저장된느 저장소(repository)를 연동
          uri: git@github.com:anonymous7planet/destiny-planet-api-config.git
          # ssh-keygen -m PEM -t ecdsa -b 256 -C "email" 2022.03.15부터 github key 알고리즘 변경
          private-key: |
                  -----BEGIN EC PRIVATE KEY-----
                  MHcCAQEEIDtcjDfQPJ7Vm2DLEBESoiAi9Xtc0RtZfqEphRqJItIvoAoGCCqGSM49
                  AwEHoUQDQgAEQ1HAgtAhT/3lVxoYgYLADYMgvYfQ4MQUeT2fHnNhLaFbw06a1liR
                  yRPZS8C8BjbhSyy6y6BUXABE4VD5hs2veQ==
                  -----END EC PRIVATE KEY-----
          search-paths: destiny-planet-discovery-server, destiny-planet-gateway-server, destiny-planet-auth-service, destiny-planet-member-service
          default-label: main
          skip-ssl-validation: true
          ignore-local-ssh-settings: true
    bus:
      enabled: true # Bus로 설정 변경 새로고침 활성화
      refresh:
        enabled: true # bus-refresh Endpoint 활성화 호출시 전체 Config Bus Client에 전송
      env:
        enabled: true
        #  spring.kafka.consumer.group-id
        #  컨슈머의 그룹 id
        #
        #  spring.kafka.consumer.enable-auto-commit
        #  데이터를 어디까지 읽었다는 offset을 주기적으로 저장할지 여부
        #
        #  spring.kafka.consumer.auto-offset-reset
        #  offset에 오류가 있을 경우 어디서 부터 다시 할지 여부
        #  ealiest : 맨처음부터 다시 읽는다
        #  latest : 이전꺼는 무시하고, 이제부터 들어오는 데이터부터 읽기 시작한다.
        #
        #  spring.kafka.producer.key-serializer
        #  데이터를 kafka로 전달할때 사용 Kety Encoder Class
        #  StringSerializer는 문자열 형태의 데이터에만
        #
        #  spring.kafka.consumer.key-deserializer
        #  데이터를 kafka에서 바아서 사용하는 Key Decoder Class
        #  StringDeserializer는 문자열 형태의 데이터에만 사용가능
        #
        #  spring.kafka.producer.value-serializer
        #  데이터를 kafka로 전달할때 사용하는 Value Encoder Class
        #  StringSerializer는 문자열 형태의 데이터에만 사용가능
        #
        #  spring.kafka.consumer.value-deserializer
        #  데이터를 kafka에서 받아서 사용하는 Value Decoder Class
        #  StringDeserializer는 문자열 형태의 데이터에만 사용가능
        #
        #  spring.kafka.consumer.max-poll-records
        #  consumer가 한번에 가져오는 message 갯수
        #
      #  spring.kafka.template.default-topic
      #  기본 설정 topic name
    kafka:
      # kafka 서버 정보, 기본적으로 9092포트를 사용
      bootstrap-servers: ${KAFKA_SERVER_HOST_NAME:127.0.0.1}:${KAFKA_SERVER_PORT:9092}
      #컨슈머 그룹
  #    consumer:
  #      group-id: test
eureka:
  client:
    service-url:
      defaultZone: http://${eureka.client.instance.user.name}:${eureka.client.instance.user.password}@${eureka.client.instance.hostname}:${eureka.client.instance.port}/eureka/
    instance:
      hostname: ${EUREKA_SERVER_HOST_NAME:localhost}
      port: ${EUREKA_SERVER_PORT:8761}
      user:
        name: admin
        password: admin
    register-with-eureka: true # 유레카 서버에 서비스 등록
    fetch-registry: true        # 레지스트리 정보를 로컬에 캐싱
    prefer-same-zone-eureka: true
    registry-fetch-interval-seconds: 10 # 서비스 목록 캐싱(default : 30초)
    disable-delta: true # 캐싱할 때 변경된 부분만 업데이트
management: # Actuator 허용 EndPoint 정의
  endpoints:
    web:
      exposure:
        include: busrefresh,refresh,httptrace,shutdown,health,prometheus,metrics
      base-path: /destiny-planet/manage
  endpoint:
    refresh:
      enabled: true
    metrics:
      enabled: true
    prometheus:
      enabled: true
  metrics:
    export:
      prometheus:
        enabled: true
    tags:
      application: ${spring.application.name}